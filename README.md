# Narrator

Live "sports announcer" narration of your computer use on macOS. Captures the active app + window, watches visual change on screen, and streams commentary through the ElevenLabs WebSocket TTS API. Narration is generated by Gemini 3 Flash.

## Setup

Create a virtualenv and install deps:

```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

Create a `.env` file:

```bash
ELEVENLABS_API_KEY=your_key_here
ELEVENLABS_VOICE_ID=your_voice_id_here
# Or use a voice name (resolved at runtime):
# ELEVENLABS_VOICE_NAME=Sportscaster
# Gemini
GEMINI_API_KEY=your_key_here
GEMINI_MODEL=gemini-3-flash-preview
GEMINI_TEMPERATURE=0.7
GEMINI_MAX_OUTPUT_TOKENS=320
GEMINI_TIMEOUT_SEC=30
GEMINI_MIN_CHARS=260
GEMINI_MIN_WORDS=42
GEMINI_MIN_SENTENCES=2
GEMINI_MAX_RETRIES=2
GEMINI_HISTORY_LINES=4
GEMINI_HISTORY_CONTEXTS=6
# Optional: override Gemini pricing ($ per 1M tokens)
GEMINI_INPUT_COST_PER_M=0.50
GEMINI_OUTPUT_COST_PER_M=3.00
# Optional
ELEVENLABS_MODEL_ID=eleven_flash_v2_5
ELEVENLABS_OUTPUT_FORMAT=pcm_16000
NARRATOR_INTERVAL_SEC=5
NARRATOR_MIN_GAP_SEC=6
NARRATOR_IGNORE_APPS=1Password,Keychain Access
NARRATOR_VERBOSE=1
# Optional: allow a small narration backlog while audio plays
NARRATOR_QUEUE_MAX=2
NARRATOR_PROFANITY=high
# Optional: suppress constraint debug lines unless explicitly enabled
NARRATOR_DEBUG_CONSTRAINTS=0
# Optional: loop a low-volume ambient WAV in the background (16-bit PCM, mono, same rate as output)
NARRATOR_AMBIENT_WAV=/path/to/crowd.wav
NARRATOR_AMBIENT_GAIN=0.08
# Optional: crossfade the ambient loop to avoid seams
NARRATOR_AMBIENT_CROSSFADE_SEC=0.25
# Optional: allow context-only fallback lines when Gemini errors or returns empty
NARRATOR_FALLBACK_MIN_GAP=3
# Optional: timeline logging for debugging (prints to stderr or file)
NARRATOR_TIMELINE=1
NARRATOR_TIMELINE_PATH=/tmp/narrator_timeline.log
# Optional: log raw Gemini responses to a file for debugging
NARRATOR_GEMINI_RAW_LOG=/tmp/narrator_gemini_raw.log
# Optional: pin capture to a specific display
NARRATOR_SCREEN_INDEX=0
NARRATOR_SCREENCAPTURE_DISPLAY=1
```

## Usage

```bash
# Gemini mode (AI-generated narration)
python -m narrator.main

# Local mode (built-in templates, no AI calls)
python -m narrator.main --local

# Dry run (print lines without speaking)
python -m narrator.main --dry-run
python -m narrator.main --local --dry-run

# Verbose debug output
python -m narrator.main --verbose

# Pin to a specific display
python -m narrator.main --screen-index 0
python -m narrator.main --display-id 1
```

## Architecture

```
┌─────────────────┐     ┌─────────────────┐     ┌─────────────┐
│  Screen Capture │────▶│   Gemini 3      │────▶│  ElevenLabs │
│ (Peekaboo/SC)   │     │  (Image+Text)   │     │    (TTS)    │
└─────────────────┘     └─────────────────┘     └─────────────┘
```

## Notes

- This MVP uses the ElevenLabs Text-to-Speech WebSocket streaming API and expects a PCM output format for real-time playback. If you change `ELEVENLABS_OUTPUT_FORMAT`, make sure it is PCM (for example, `pcm_16000`).
- Eleven v3 models do not support WebSocket streaming; use a v2.5 model (like `eleven_flash_v2_5`) for this app.
- If you see a permissions error, open System Settings > Privacy & Security and grant Screen Recording + Accessibility to your terminal or Python executable.
- Use `NARRATOR_SCREEN_INDEX` (Peekaboo) or `NARRATOR_SCREENCAPTURE_DISPLAY` (screencapture) to force the main monitor if defaults pick the wrong one.
- When running with `--verbose`, the app prints a live Gemini cost estimate using usage metadata. Override pricing with `GEMINI_INPUT_COST_PER_M` and `GEMINI_OUTPUT_COST_PER_M` if you use a model not in the built-in map.

## Tests

```bash
python -m unittest discover -s tests
```
